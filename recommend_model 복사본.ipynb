{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8423c58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import ctypes\n",
    "import joblib\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRanker\n",
    "from lightgbm import LGBMRanker, log_evaluation, early_stopping\n",
    "import random\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80ad91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"광고목록_전처리.csv\")\n",
    "df2 = pd.read_csv(\"광고적립_전처리.csv\")\n",
    "df3 = pd.read_csv(\"진짜_시간별_1년치_전처리_0910.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0af670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[['ads_idx', 'ads_category', 'ads_type','ads_code']]\n",
    "df2 = df2[['ads_idx', 'adv_cost', 'earn_cost', 'mda_idx']]\n",
    "df3 = df3[['ads_idx', 'mda_idx', 'rpt_time_date', 'rpt_time_time', 'rpt_time_clk', 'rpt_time_turn']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1524300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['rpt_time_date'] = pd.to_datetime(df3['rpt_time_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86154f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df1, df2, on=\"ads_idx\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df,df3, on=[\"ads_idx\", \"mda_idx\"],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401932be",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1, df2, df3\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a648662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63672284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df, verbose=True):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object and not pd.api.types.is_datetime64_any_dtype(col_type):\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "\n",
    "        elif col_type == object:\n",
    "            num_unique = df[col].nunique()\n",
    "            num_total = len(df[col])\n",
    "            if num_unique / num_total < 0.5:\n",
    "                df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose:\n",
    "        print(f'Memory usage decreased from {start_mem:.2f} MB to {end_mem:.2f} MB '\n",
    "              f'({100 * (start_mem - end_mem) / start_mem:.1f}% reduction)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d4e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"margin\"] = df[\"adv_cost\"] - df[\"earn_cost\"]\n",
    "df[\"margin_rate\"] = ((df[\"margin\"] / df[\"adv_cost\"]) * 100).round(2)\n",
    "df['margin_rate'] = df['margin_rate'].replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee85a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_by_media_category = df.groupby([\"mda_idx\", \"ads_category\"]).agg({\"adv_cost\": \"sum\", \"earn_cost\": \"sum\"}).reset_index()\n",
    "\n",
    "margin_by_media_category[\"margin\"] = (margin_by_media_category[\"adv_cost\"] - margin_by_media_category[\"earn_cost\"])\n",
    "\n",
    "margin_by_media_category[\"margin_rate\"] = ((margin_by_media_category[\"margin\"] / margin_by_media_category[\"adv_cost\"]) * 100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7285700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = pd.to_numeric(df['rpt_time_time'], errors=\"coerce\").fillna(0).astype('int16')\n",
    "\n",
    "df['time_period_encoded'] = pd.cut(\n",
    "    df['hour'],\n",
    "    bins=[-1, 5, 11, 17, 23],\n",
    "    labels=[0, 1, 2, 3]\n",
    ").astype('int8')\n",
    "\n",
    "df['CVR'] = np.where(\n",
    "    (df['rpt_time_clk'] > 0) & df['rpt_time_turn'].notna(),\n",
    "    (df['rpt_time_turn'] / df['rpt_time_clk'] * 100),\n",
    "    np.nan\n",
    ").astype('float32')\n",
    "\n",
    "df['rpt_time_date'] = pd.to_datetime(df['rpt_time_date'], errors=\"coerce\")\n",
    "df['day_of_week'] = df['rpt_time_date'].dt.dayofweek.astype('int8')\n",
    "df['is_weekend'] = (df['day_of_week'] >= 5).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d6b3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be0251f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rpt_time_date'] = pd.to_datetime(df['rpt_time_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3390b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'rpt_time_date' in df.columns:\n",
    "    del df['rpt_time_date']\n",
    "\n",
    "if 'rpt_time_time' in df.columns:\n",
    "    del df['rpt_time_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a63b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == \"int64\":\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "    elif df[col].dtype == \"float64\":\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fbfd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f1d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['rpt_time_turn']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f4f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN 개수:\", df['margin_rate'].isna().sum())\n",
    "print(\"Inf 개수:\", np.isinf(df['margin_rate']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5219025",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if df[col].dtype == \"int64\":\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
    "    elif df[col].dtype == \"float64\":\n",
    "        df[col] = pd.to_numeric(df[col], downcast=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89dcb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd3a1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df1, df2, df3\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140066b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "req_cols=[\"mda_idx\",\"CVR\",\"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\",\"ads_code\",\"ads_type\",\"ads_category\"]\n",
    "if \"time_period\" in df.columns: \n",
    "    req_cols.append(\"time_period\")\n",
    "df=df[req_cols].copy()\n",
    "\n",
    "for c in df.select_dtypes(include=[\"float64\"]).columns: \n",
    "    df[c]=pd.to_numeric(df[c],downcast=\"float\")\n",
    "for c in df.select_dtypes(include=[\"int64\"]).columns: \n",
    "    df[c]=pd.to_numeric(df[c],downcast=\"integer\")\n",
    "\n",
    "df[\"CVR\"]=pd.to_numeric(df[\"CVR\"],errors=\"coerce\").fillna(0.0)\n",
    "df[\"margin_rate\"]=pd.to_numeric(df[\"margin_rate\"],errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "mda_stats=(df.groupby(\"mda_idx\")\n",
    "             .agg(n_rows=(\"mda_idx\",\"size\"),mean_cvr=(\"CVR\",\"mean\"))\n",
    "             .reset_index())\n",
    "\n",
    "cvr_thresh=mda_stats[\"mean_cvr\"].quantile(0.7)\n",
    "rows_thresh=mda_stats[\"n_rows\"].quantile(0.7)\n",
    "\n",
    "def assign_group(row):\n",
    "    if row[\"mean_cvr\"]>=cvr_thresh and row[\"n_rows\"]>=rows_thresh: \n",
    "        return \"A_high_perf_big\"\n",
    "    elif row[\"mean_cvr\"]>=cvr_thresh: \n",
    "        return \"B_high_perf_small\"\n",
    "    elif row[\"n_rows\"]>=rows_thresh: \n",
    "        return \"C_low_perf_big\"\n",
    "    else: \n",
    "        return \"D_low_perf_small\"\n",
    "\n",
    "mda_stats[\"group\"]=mda_stats.apply(assign_group,axis=1)\n",
    "df=df.merge(mda_stats[[\"mda_idx\",\"group\"]],on=\"mda_idx\",how=\"left\")\n",
    "\n",
    "le_ads=LabelEncoder().fit(df[\"ads_code\"].astype(str))\n",
    "le_type=LabelEncoder().fit(df[\"ads_type\"].astype(str))\n",
    "le_cat=LabelEncoder().fit(df[\"ads_category\"].astype(str))\n",
    "le_time=None\n",
    "if \"time_period\" in df.columns: \n",
    "    le_time=LabelEncoder().fit(df[\"time_period\"].astype(str))\n",
    "\n",
    "df[\"ads_code_encoded\"]=le_ads.transform(df[\"ads_code\"].astype(str))\n",
    "df[\"ads_type_encoded\"]=le_type.transform(df[\"ads_type\"].astype(str))\n",
    "df[\"ads_category_encoded\"]=le_cat.transform(df[\"ads_category\"].astype(str))\n",
    "if le_time is not None: \n",
    "    df[\"time_period_encoded\"]=le_time.transform(df[\"time_period\"].astype(str))\n",
    "\n",
    "for g in df[\"group\"].unique():\n",
    "    gdf=df[df[\"group\"]==g].copy()\n",
    "    if len(gdf)==0: \n",
    "        continue\n",
    "    fname=f\"dataset_{g}.parquet\"\n",
    "    gdf.to_parquet(fname,index=False)\n",
    "    print(f\"{g}: {fname} 저장 완료 (rows={len(gdf)})\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1800af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRanker\n",
    "from xgboost.callback import EarlyStopping\n",
    "import joblib\n",
    "\n",
    "df_a = pd.read_parquet(\"dataset_A_high_perf_big.parquet\")\n",
    "\n",
    "X = df_a[[\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]]\n",
    "\n",
    "df_a[\"label\"] = pd.qcut(df_a[\"target_score\"], q=3, labels=False, duplicates=\"drop\")\n",
    "y = df_a[\"label\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "group_train = df_a.loc[X_train.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "group_test  = df_a.loc[X_test.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "\n",
    "ranker_A = XGBRanker(\n",
    "    objective=\"rank:ndcg\",\n",
    "    eval_metric=\"ndcg@10\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=100,\n",
    "    max_depth=3,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42)\n",
    "\n",
    "ranker_A.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[group_test],\n",
    "    #early_stopping_rounds=20,\n",
    "    verbose=True)\n",
    "\n",
    "joblib.dump(ranker_A, \"xgb_ranker_A.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce507a",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059acce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRanker\n",
    "from xgboost.callback import EarlyStopping\n",
    "import joblib\n",
    "\n",
    "df_B = pd.read_parquet(\"dataset_B_high_perf_small.parquet\")\n",
    "\n",
    "X = df_B[[\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]]\n",
    "\n",
    "df_B[\"label\"] = pd.qcut(df_B[\"target_score\"], q=3, labels=False, duplicates=\"drop\")\n",
    "y = df_B[\"label\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "group_train = df_B.loc[X_train.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "group_test  = df_B.loc[X_test.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "\n",
    "ranker_B = XGBRanker(\n",
    "    objective=\"rank:ndcg\",\n",
    "    eval_metric=\"ndcg@10\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.08,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42)\n",
    "\n",
    "ranker_B.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[group_test],\n",
    "    #early_stopping_rounds=20,\n",
    "    verbose=True)\n",
    "\n",
    "joblib.dump(ranker_B, \"xgb_ranker_B.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05195c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ba43fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRanker\n",
    "import joblib\n",
    "\n",
    "df_C = pd.read_parquet(\"dataset_C_low_perf_big.parquet\")\n",
    "\n",
    "X = df_C[[\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]]\n",
    "\n",
    "df_C[\"label\"] = pd.qcut(df_C[\"target_score\"], q=8, labels=False, duplicates=\"drop\").astype(int)\n",
    "#df_C[\"label\"] = pd.qcut(df_C[\"target_score\"], q=3, labels=False, duplicates=\"drop\")\n",
    "y = df_C[\"label\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "group_train = df_C.loc[X_train.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "group_test  = df_C.loc[X_test.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "\n",
    "ranker_C = XGBRanker(\n",
    "    objective=\"rank:ndcg\",\n",
    "    eval_metric=\"ndcg@10\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=10,\n",
    "    reg_lambda=1.0,\n",
    "    reg_alpha=0.1,\n",
    "    random_state=42)\n",
    "\n",
    "ranker_C.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[group_test],\n",
    "    #early_stopping_rounds=20,\n",
    "    verbose=True)\n",
    "\n",
    "joblib.dump(ranker_C, \"xgb_ranker_C.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c544085",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db89c918",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBRanker\n",
    "import joblib\n",
    "\n",
    "df_D = pd.read_parquet(\"dataset_D_low_perf_small.parquet\")\n",
    "\n",
    "X = df_D[[\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]]\n",
    "\n",
    "df_D[\"label\"] = pd.qcut(df_D[\"target_score\"], q=3, labels=False, duplicates=\"drop\")\n",
    "y = df_D[\"label\"].astype(int)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "group_train = df_D.loc[X_train.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "group_test  = df_D.loc[X_test.index].groupby(\"mda_idx\").size().to_numpy()\n",
    "\n",
    "ranker_D = XGBRanker(\n",
    "    objective=\"rank:ndcg\",\n",
    "    eval_metric=\"ndcg@10\",\n",
    "    tree_method=\"hist\",\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.04,\n",
    "    subsample=0.9\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_weight=5,\n",
    "    reg_alpha=0.2,\n",
    "    reg_lambda=8.0,\n",
    "    gamma=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "ranker_D.fit(\n",
    "    X_train, y_train,\n",
    "    group=group_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_group=[group_test],\n",
    "    #early_stopping_rounds=100,\n",
    "    verbose=True)\n",
    "\n",
    "joblib.dump(ranker_D, \"xgb_ranker_D.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b535ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "ranker_A = joblib.load(\"xgb_ranker_A.pkl\")\n",
    "df_A = pd.read_parquet(\"dataset_A_high_perf_big.parquet\")\n",
    "\n",
    "feat_cols = [\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\n",
    "             \"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]\n",
    "X_A = df_A[feat_cols]\n",
    "\n",
    "# X_A = X_A.sample(5000, random_state=42)\n",
    "\n",
    "booster = ranker_A.get_booster()\n",
    "importance_gain = booster.get_score(importance_type=\"gain\")\n",
    "print(\"Gain 기반 중요도:\", importance_gain)\n",
    "\n",
    "xgb.plot_importance(ranker_A, importance_type=\"gain\")\n",
    "plt.show()\n",
    "\n",
    "explainer = shap.TreeExplainer(ranker_A)\n",
    "shap_values = explainer.shap_values(X_A)\n",
    "\n",
    "shap.summary_plot(shap_values, X_A)\n",
    "shap.dependence_plot(\"margin_rate\", shap_values, X_A)\n",
    "shap.dependence_plot(\"adv_cost\", shap_values, X_A)\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_A.columns,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "print(\"\\n평균 절대 SHAP 값 기반 중요도:\")\n",
    "print(shap_importance)\n",
    "\n",
    "print(\"\\n=== 인사이트 요약 ===\")\n",
    "top_feat = shap_importance.iloc[0][\"feature\"]\n",
    "print(f\"모델이 가장 민감하게 반응하는 변수는 '{top_feat}' 입니다.\")\n",
    "\n",
    "for i, row in shap_importance.iterrows():\n",
    "    feat = row[\"feature\"]\n",
    "    score = row[\"mean_abs_shap\"]\n",
    "    print(f\"- {feat}: 평균 SHAP 영향력 {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74472efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "ranker_B = joblib.load(\"xgb_ranker_B.pkl\")\n",
    "df_B = pd.read_parquet(\"dataset_B_high_perf_small.parquet\")\n",
    "\n",
    "feat_cols = [\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\n",
    "             \"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]\n",
    "X_B = df_B[feat_cols]\n",
    "\n",
    "# X_B = X_B.sample(5000, random_state=42)\n",
    "\n",
    "booster = ranker_B.get_booster()\n",
    "importance_gain = booster.get_score(importance_type=\"gain\")\n",
    "print(\"Gain 기반 중요도:\", importance_gain)\n",
    "\n",
    "xgb.plot_importance(ranker_B, importance_type=\"gain\")\n",
    "plt.show()\n",
    "\n",
    "explainer = shap.TreeExplainer(ranker_B)\n",
    "shap_values = explainer.shap_values(X_B)\n",
    "\n",
    "shap.summary_plot(shap_values, X_B)\n",
    "shap.dependence_plot(\"margin_rate\", shap_values, X_B)\n",
    "shap.dependence_plot(\"adv_cost\", shap_values, X_B)\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_B.columns,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "print(\"\\n평균 절대 SHAP 값 기반 중요도:\")\n",
    "print(shap_importance)\n",
    "\n",
    "print(\"\\n=== 인사이트 요약 ===\")\n",
    "top_feat = shap_importance.iloc[0][\"feature\"]\n",
    "print(f\"모델이 가장 민감하게 반응하는 변수는 '{top_feat}' 입니다.\")\n",
    "\n",
    "for i, row in shap_importance.iterrows():\n",
    "    feat = row[\"feature\"]\n",
    "    score = row[\"mean_abs_shap\"]\n",
    "    print(f\"- {feat}: 평균 SHAP 영향력 {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054ec55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "ranker_C = joblib.load(\"xgb_ranker_C.pkl\")\n",
    "df_C = pd.read_parquet(\"dataset_C_low_perf_big.parquet\")\n",
    "\n",
    "feat_cols = [\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\n",
    "             \"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]\n",
    "X_C = df_C[feat_cols]\n",
    "\n",
    "# X_C = X_C.sample(5000, random_state=42)\n",
    "\n",
    "booster = ranker_C.get_booster()\n",
    "importance_gain = booster.get_score(importance_type=\"gain\")\n",
    "print(\"Gain 기반 중요도:\", importance_gain)\n",
    "\n",
    "xgb.plot_importance(ranker_C, importance_type=\"gain\")\n",
    "plt.show()\n",
    "\n",
    "explainer = shap.TreeExplainer(ranker_C)\n",
    "shap_values = explainer.shap_values(X_C)\n",
    "\n",
    "shap.summary_plot(shap_values, X_C)\n",
    "shap.dependence_plot(\"margin_rate\", shap_values, X_C)\n",
    "shap.dependence_plot(\"adv_cost\", shap_values, X_C)\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_C.columns,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "print(\"\\n평균 절대 SHAP 값 기반 중요도:\")\n",
    "print(shap_importance)\n",
    "\n",
    "print(\"\\n=== 인사이트 요약 ===\")\n",
    "top_feat = shap_importance.iloc[0][\"feature\"]\n",
    "print(f\"모델이 가장 민감하게 반응하는 변수는 '{top_feat}' 입니다.\")\n",
    "\n",
    "for i, row in shap_importance.iterrows():\n",
    "    feat = row[\"feature\"]\n",
    "    score = row[\"mean_abs_shap\"]\n",
    "    print(f\"- {feat}: 평균 SHAP 영향력 {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "ranker_D = joblib.load(\"xgb_ranker_D.pkl\")\n",
    "df_D = pd.read_parquet(\"dataset_D_low_perf_small.parquet\")\n",
    "\n",
    "feat_cols = [\"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\n",
    "             \"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]\n",
    "X_D = df_D[feat_cols]\n",
    "\n",
    "# X_D = X_D.sample(5000, random_state=42)\n",
    "\n",
    "booster = ranker_D.get_booster()\n",
    "importance_gain = booster.get_score(importance_type=\"gain\")\n",
    "print(\"Gain 기반 중요도:\", importance_gain)\n",
    "\n",
    "xgb.plot_importance(ranker_D, importance_type=\"gain\")\n",
    "plt.show()\n",
    "\n",
    "explainer = shap.TreeExplainer(ranker_D)\n",
    "shap_values = explainer.shap_values(X_D)\n",
    "\n",
    "shap.summary_plot(shap_values, X_D)\n",
    "shap.dependence_plot(\"margin_rate\", shap_values, X_D)\n",
    "shap.dependence_plot(\"adv_cost\", shap_values, X_D)\n",
    "\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "shap_importance = pd.DataFrame({\n",
    "    \"feature\": X_D.columns,\n",
    "    \"mean_abs_shap\": mean_abs_shap\n",
    "}).sort_values(\"mean_abs_shap\", ascending=False)\n",
    "print(\"\\n평균 절대 SHAP 값 기반 중요도:\")\n",
    "print(shap_importance)\n",
    "\n",
    "print(\"\\n=== 인사이트 요약 ===\")\n",
    "top_feat = shap_importance.iloc[0][\"feature\"]\n",
    "print(f\"모델이 가장 민감하게 반응하는 변수는 '{top_feat}' 입니다.\")\n",
    "\n",
    "for i, row in shap_importance.iterrows():\n",
    "    feat = row[\"feature\"]\n",
    "    score = row[\"mean_abs_shap\"]\n",
    "    print(f\"- {feat}: 평균 SHAP 영향력 {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed1e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_A = pd.read_parquet(\"dataset_A_high_perf_big.parquet\"); df_A[\"group\"] = \"A\"\n",
    "df_B = pd.read_parquet(\"dataset_B_high_perf_small.parquet\"); df_B[\"group\"] = \"B\"\n",
    "df_C = pd.read_parquet(\"dataset_C_low_perf_big.parquet\"); df_C[\"group\"] = \"C\"\n",
    "df_D = pd.read_parquet(\"dataset_D_low_perf_small.parquet\"); df_D[\"group\"] = \"D\"\n",
    "\n",
    "df = pd.concat([df_A, df_B, df_C, df_D], ignore_index=True)\n",
    "\n",
    "df[\"ROAS\"] = df[\"earn_cost\"] / df[\"adv_cost\"].replace(0, 1)\n",
    "df[\"profitability\"] = (df[\"earn_cost\"] - df[\"adv_cost\"]) / df[\"adv_cost\"].replace(0, 1)\n",
    "if \"model_score\" not in df.columns and \"target_score\" in df.columns:\n",
    "    df[\"model_score\"] = df[\"target_score\"]\n",
    "\n",
    "combo_summary = (\n",
    "    df.groupby([\"group\", \"mda_idx\", \"ads_category\", \"ads_type\"])\n",
    "      .agg(\n",
    "          mean_margin_rate=(\"margin_rate\", \"mean\"),\n",
    "          mean_roas=(\"ROAS\", \"mean\"),\n",
    "          total_earn=(\"earn_cost\", \"sum\"),\n",
    "          total_adv=(\"adv_cost\", \"sum\"),\n",
    "          mean_score=(\"model_score\", \"mean\")).reset_index())\n",
    "\n",
    "best_combos = (\n",
    "    combo_summary.sort_values(\n",
    "        by=[\"mean_score\", \"mean_roas\", \"mean_margin_rate\", \"total_earn\"],\n",
    "        ascending=[False, False, False, False])\n",
    "    .groupby([\"group\", \"mda_idx\"])\n",
    "    .head(1)\n",
    "    .reset_index(drop=True))\n",
    "\n",
    "best_combos_sorted = best_combos.sort_values(\n",
    "    by=[\"group\", \"mean_score\", \"mean_roas\", \"mean_margin_rate\", \"total_earn\"],\n",
    "    ascending=[True, False, False, False, False])\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "\n",
    "print(\"\\n=== 그룹별 mda_idx 최고의 조합 (카테고리 + 타입) ===\")\n",
    "print(best_combos_sorted[[\"group\", \"mda_idx\", \"ads_category\", \"ads_type\", \n",
    "                          \"mean_score\", \"mean_roas\", \"mean_margin_rate\", \"total_earn\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252061ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "\n",
    "def recommend_media(model_path, df_input, top_n=5):\n",
    "    ranker = joblib.load(model_path)\n",
    "    df_input[\"margin\"] = df_input[\"adv_cost\"] - df_input[\"earn_cost\"]\n",
    "    df_input[\"margin_rate\"] = df_input[\"margin\"] / df_input[\"adv_cost\"].replace(0, 1)\n",
    "    feat_cols = [\n",
    "        \"ads_code_encoded\",\"ads_type_encoded\",\"ads_category_encoded\",\n",
    "        \"adv_cost\",\"earn_cost\",\"margin\",\"margin_rate\"]\n",
    "    X = df_input[feat_cols]\n",
    "\n",
    "    groups = df_input.groupby(\"mda_idx\").size().to_numpy()\n",
    "\n",
    "    dtest = xgb.DMatrix(X)\n",
    "    dtest.set_group(groups)\n",
    "\n",
    "    preds = ranker.get_booster().predict(dtest)\n",
    "    df_input[\"pred_score\"] = preds\n",
    "\n",
    "    recommendations = (\n",
    "        df_input.sort_values([\"mda_idx\",\"pred_score\"], ascending=[True,False])\n",
    "                .groupby(\"mda_idx\")\n",
    "                .head(top_n))\n",
    "    return recommendations[[\"mda_idx\",\"ads_code_encoded\",\"pred_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f2096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = pd.DataFrame({\n",
    "#     \"mda_idx\": [1,1,1,2,2],\n",
    "#     \"ads_code_encoded\": [101,102,103,201,202],\n",
    "#     \"ads_type_encoded\": [1,2,1,3,2],\n",
    "#     \"ads_category_encoded\": [10,11,12,20,21],\n",
    "#     \"adv_cost\": [120.0,150.0,90.0,200.0,180.0],\n",
    "#     \"earn_cost\": [70.0,80.0,50.0,120.0,100.0]})\n",
    "\n",
    "# recommendations = recommend_media(\"xgb_ranker_A.pkl\", df_new, top_n=2)\n",
    "\n",
    "# print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
